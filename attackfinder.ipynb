{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the dataset\n",
    "dataset_path = './testing'\n",
    "\n",
    "# Create a list of file paths to the images\n",
    "image_paths = [os.path.join(dataset_path, file) for file in os.listdir(dataset_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./testing\\\\heatmap_0.png',\n",
       " './testing\\\\heatmap_1.png',\n",
       " './testing\\\\heatmap_2.png',\n",
       " './testing\\\\heatmap_3.png',\n",
       " './testing\\\\heatmap_4.png',\n",
       " './testing\\\\heatmap_5.png']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of labels for each image\n",
    "labels = [int(os.path.splitext(os.path.basename(path))[0].split('_')[-1]) for path in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(500,500, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to load and preprocess an image\n",
    "def load_and_preprocess_image(path, label):\n",
    "    # Load the image\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    # Preprocess the image\n",
    "    image = tf.image.resize(image, (500, 500))\n",
    "    image /= 255.0\n",
    "    return image, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(image_paths, labels, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['./testing\\\\heatmap_5.png',\n",
       "  './testing\\\\heatmap_2.png',\n",
       "  './testing\\\\heatmap_4.png',\n",
       "  './testing\\\\heatmap_3.png'],\n",
       " ['./testing\\\\heatmap_0.png', './testing\\\\heatmap_1.png'],\n",
       " [5, 2, 4, 3],\n",
       " [0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths, val_paths, train_labels, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `tf.data` API to create datasets from the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the `load_and_preprocess_image` function over each element in the dataset\n",
    "train_dataset = train_dataset.map(load_and_preprocess_image)\n",
    "val_dataset = val_dataset.map(load_and_preprocess_image)\n",
    "\n",
    "# Batch the data\n",
    "train_dataset = train_dataset.batch(32)\n",
    "val_dataset = val_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the folder containing the heatmaps\n",
    "heatmap_folder = './resm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the heatmap filenames in the folder\n",
    "heatmap_filenames = os.listdir(heatmap_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each heatmap as an image\n",
    "heatmaps = []\n",
    "for filename in heatmap_filenames:\n",
    "    filepath = os.path.join(heatmap_folder, filename)\n",
    "    heatmap = Image.open(filepath)\n",
    "    heatmaps.append(np.array(heatmap))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the labels from the file names\n",
    "labels = []\n",
    "for name in heatmap_filenames:\n",
    "    l = name.index('_') + 1\n",
    "    r = name.index('.')\n",
    "    class_id = int(name[l:r])\n",
    "    labels.append(class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of heatmaps into a numpy array\n",
    "heatmaps = np.array(heatmaps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the heatmaps if necessary\n",
    "heatmaps = heatmaps / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "train_data = heatmaps[:int(heatmaps.shape[0] * 0.7)]\n",
    "val_data = heatmaps[int(heatmaps.shape[0] * 0.7):int(heatmaps.shape[0] * 0.9)]\n",
    "test_data = heatmaps[int(heatmaps.shape[0] * 0.9):]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the labels into training, validation, and test sets\n",
    "train_labels = labels[:int(len(labels) * 0.7)]\n",
    "val_labels = labels[int(len(labels) * 0.7):int(len(labels) * 0.9)]\n",
    "test_labels = labels[int(len(labels) * 0.9):]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the architecture of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture of the CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu',\n",
    "          input_shape=heatmaps.shape[1:]))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_data, epochs=10, batch_size=32,\n",
    "                    validation_data=(val_data, val_labels))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adba5ac529c27a993592bfcf9d1626d7924805d09a935804b26a69a178afdf1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
